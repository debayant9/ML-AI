{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WeVM3bNw1aq"
   },
   "source": [
    "# Telecom Churn - Case Study\n",
    "##### By: Kirti Gupta & Debayan Talapatra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1VghQ7YBw1as"
   },
   "source": [
    "###### Business Problem Statement\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    "For many incumbent operators, retaining high profitable customers is the number one business goal.\n",
    "To reduce customer churn, telecom companies need to predict which customers are at high risk of churn.\n",
    "\n",
    "In this project, you will analyse customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn and identify the main indicators of churn.\n",
    "\n",
    "\n",
    "##### Defining Churn\n",
    "There are two main models of payment in the telecom industry - **postpaid** (customers pay a monthly/annual bill after using the services) and **prepaid** (customers pay/recharge with a certain amount in advance and then use the services).\n",
    "\n",
    "In the postpaid model, when customers want to switch to another operator, they usually inform the existing operator to terminate the services, and you directly know that this is an instance of churn.\n",
    "\n",
    "However, in the prepaid model, customers who want to switch to another network can simply stop using the services without any notice, and it is hard to know whether someone has actually churned or is simply not using the services temporarily (e.g. someone may be on a trip abroad for a month or two and then intend to resume using the services again).\n",
    "\n",
    "Thus, churn prediction is usually more critical (and non-trivial) for prepaid customers, and the term ‘churn’ should be defined carefully.  Also, prepaid is the most common model in India and southeast Asia, while postpaid is more common in Europe in North America.\n",
    "\n",
    "###### Definitions of Churn\n",
    "Definitions of Churn\n",
    "There are various ways to define churn, such as:\n",
    "\n",
    "###### Revenue-based churn: \n",
    "Customers who have not utilised any revenue-generating facilities such as mobile internet, outgoing calls, SMS etc. over a given period of time. One could also use aggregate metrics such as ‘customers who have generated less than INR 4 per month in total/average/median revenue’.\n",
    "\n",
    " \n",
    "The main shortcoming of this definition is that there are customers who only receive calls/SMSes from their wage-earning counterparts, i.e. they don’t generate revenue but use the services. For example, many users in rural areas only receive calls from their wage-earning siblings in urban areas.\n",
    "\n",
    "###### High-value Churn\n",
    "In the Indian and the southeast Asian market, approximately 80% of revenue comes from the top 20% customers (called high-value customers). Thus, if we can reduce churn of the high-value customers, we will be able to reduce significant revenue leakage.\n",
    "\n",
    "\n",
    "###### Business Objective \n",
    "The business objective is to predict the churn in the last (i.e. the ninth) month using the data (features) from the first three months. To do this task well, understanding the typical customer behaviour during churn will be helpful.\n",
    "\n",
    "#### DataSet\n",
    "The dataset contains customer-level information for a span of four consecutive months - June, July, August and September. The months are encoded as 6, 7, 8 and 9, respectively.\n",
    "\n",
    "**Dataset name:** telecom_churn_data.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xeo3lJ_yw1at"
   },
   "source": [
    "###### Understanding Customer Behaviour During Churn\n",
    "Customers usually do not decide to switch to another competitor instantly, but rather over a period of time (this is especially applicable to high-value customers). In churn prediction, we assume that there are three phases of customer lifecycle :\n",
    "\n",
    "The ‘good’ phase: In this phase, the customer is happy with the service and behaves as usual.\n",
    "\n",
    "The ‘action’ phase: The customer experience starts to sore in this phase, for e.g. he/she gets a compelling offer from a  competitor, faces unjust charges, becomes unhappy with service quality etc. In this phase, the customer usually shows different behaviour than the ‘good’ months. Also, it is crucial to identify high-churn-risk customers in this phase, since some corrective actions can be taken at this point (such as matching the competitor’s offer/improving the service quality etc.)\n",
    "\n",
    "The ‘churn’ phase: In this phase, the customer is said to have churned. You define churn based on this phase. Also, it is important to note that at the time of prediction (i.e. the action months), this data is not available to you for prediction. Thus, after tagging churn as 1/0 based on this phase, you discard all data corresponding to this phase.\n",
    "\n",
    " \n",
    "\n",
    "In this case, since you are working over a four-month window, the first two months are the ‘good’ phase, the third month is the ‘action’ phase, while the fourth month is the ‘churn’ phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BjiQL76jw1av"
   },
   "source": [
    "# Data Reading and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvPhyxKZw1az"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2roMMJbw1a6",
    "outputId": "ac71a6eb-4be3-465e-f301-9dabcbd9bc9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>last_date_of_month_9</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>...</th>\n",
       "      <th>sachet_3g_9</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>fb_user_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000842753</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>197.385</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>968</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001865778</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>34.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7001625959</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>167.690</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7001204172</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>221.338</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000142493</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>261.636</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0     7000842753        109             0.0             0.0             0.0   \n",
       "1     7001865778        109             0.0             0.0             0.0   \n",
       "2     7001625959        109             0.0             0.0             0.0   \n",
       "3     7001204172        109             0.0             0.0             0.0   \n",
       "4     7000142493        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   \n",
       "1            6/30/2014            7/31/2014            8/31/2014   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   \n",
       "4            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "  last_date_of_month_9   arpu_6  ...  sachet_3g_9  fb_user_6  fb_user_7  \\\n",
       "0            9/30/2014  197.385  ...            0        1.0        1.0   \n",
       "1            9/30/2014   34.047  ...            0        NaN        1.0   \n",
       "2            9/30/2014  167.690  ...            0        NaN        NaN   \n",
       "3            9/30/2014  221.338  ...            0        NaN        NaN   \n",
       "4            9/30/2014  261.636  ...            0        0.0        NaN   \n",
       "\n",
       "   fb_user_8  fb_user_9   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  sep_vbc_3g  \n",
       "0        1.0        NaN   968        30.4         0.0      101.20        3.58  \n",
       "1        1.0        NaN  1006         0.0         0.0        0.00        0.00  \n",
       "2        NaN        1.0  1103         0.0         0.0        4.17        0.00  \n",
       "3        NaN        NaN  2491         0.0         0.0        0.00        0.00  \n",
       "4        NaN        NaN  1526         0.0         0.0        0.00        0.00  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading dataset\n",
    "churn= pd.read_csv('telecom_churn_data.csv')\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thaqLR4ww1bF",
    "outputId": "f1fefc3a-db74-4355-c1bd-bc9022fa1af4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99999, 226)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Shape\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99999 entries, 0 to 99998\n",
      "Columns: 226 entries, mobile_number to sep_vbc_3g\n",
      "dtypes: float64(179), int64(35), object(12)\n",
      "memory usage: 172.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check DataType\n",
    "churn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Calculations\n",
    "churn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DSFhG0VQw1bO",
    "outputId": "eba5db71-2be3-4c6c-ac0f-768987f58437"
   },
   "outputs": [],
   "source": [
    "print (\"Total Features %d \"% (churn.shape[1]))\n",
    "print (\"Unique customers: %d\"%len(churn.mobile_number.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pfKES94-w1bT",
    "outputId": "bf5788b2-e604-4c1c-daa6-a54d3675676c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#columns name\n",
    "pd.DataFrame(churn.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IyfWdSy4w1bZ"
   },
   "source": [
    "##  Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgfFK9pzw1ba"
   },
   "source": [
    "##### Function to get missing/nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-w7VwT9Sw1bd"
   },
   "outputs": [],
   "source": [
    "def get_nan_values(nanCutoff):\n",
    "    # argument: nanCutoff:- % threshold for missing/nan values\n",
    "    nan_values = round(100*(churn.isnull().sum()/churn.shape[0]))\n",
    "    return nan_values.loc[nan_values > nanCutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to impute missing/nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vpKT6Evow1bg"
   },
   "outputs": [],
   "source": [
    "def impute_nan_values(data,imputedList=False,nan_list=False):\n",
    "    # argument: imputedList, list for which nan is to be replaced with 0\n",
    "    if imputedList:\n",
    "        for col in [y + s for s in ['_6','_7','_8','_9'] for y in imputedList]:\n",
    "            data[col].fillna(0, inplace=True)\n",
    "    else:    \n",
    "        for col in nan_list:\n",
    "            data[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_YDMY8Dw1bj"
   },
   "source": [
    "##### Handling missing values/Entries\n",
    "##### check  missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sKonDVuKw1bk",
    "outputId": "f8c6a5f2-13ca-4bc3-d6f9-f2589ddab768",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# missing/nan values more than 50%\n",
    "get_nan_values(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-lu8wY4w1bq"
   },
   "source": [
    "Out the these 40 features, some of them are required for Data analysis.We can impute these values for now for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qHQktPDgw1br"
   },
   "outputs": [],
   "source": [
    "# 'av_rech_amt_data', 'arpu_2g', 'arpu_3g', 'count_rech_2g', 'count_rech_3g',\n",
    "# 'max_rech_data', 'total_rech_data','fb_user','night_pck_user \n",
    "#features are important for getting the high-value customers,\n",
    "#impute  missing values with 0\n",
    "\n",
    "impute_highValueCols = ['av_rech_amt_data', 'arpu_2g', 'arpu_3g', 'count_rech_2g', 'count_rech_3g',\n",
    "             'max_rech_data', 'total_rech_data','fb_user','night_pck_user']\n",
    "impute_nan_values(churn,impute_highValueCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4b7vA2Fcw1bu",
    "outputId": "7479dd37-701b-445d-c0f3-9914d29134ee"
   },
   "outputs": [],
   "source": [
    "get_nan_values(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgznSmO-w1bz",
    "outputId": "26e405da-2af4-4b2b-cabd-646b3eb8c696"
   },
   "outputs": [],
   "source": [
    "# dropping rest of the columns having more than 50% missing values\n",
    "nan_columns = list(get_nan_values(50).index)\n",
    "churn.drop(nan_columns,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing/nan values more than 30%\n",
    "get_nan_values(30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing/nan values more than 10%\n",
    "get_nan_values(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVbTUyRUw1b7",
    "outputId": "f449d7bc-4c9d-4943-b39c-063dc0bb73d4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# missing/nan values more than 5%\n",
    "get_nan_values(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AymtxYWMw1cD"
   },
   "source": [
    "from above data :- all features for the month september(9th) have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSWl9fQrw1cG",
    "outputId": "8ebac937-5cd3-44d4-8b2f-a9f0757c19a2"
   },
   "outputs": [],
   "source": [
    "# Column/Features which have more tah 5% missing value\n",
    "nan_columns = list(get_nan_values(5).index)\n",
    "print(nan_columns)\n",
    "churn[churn[nan_columns].isnull().all(axis=1)][nan_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPK0k-Cpw1cU"
   },
   "source": [
    "##### above features can be imputed with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0lN0Ocbw1cV"
   },
   "outputs": [],
   "source": [
    "impute_nan_values(churn,nan_list=nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ze7632LVw1cZ",
    "outputId": "348e34ba-7e49-4d77-a4eb-bea939cd7a2e"
   },
   "outputs": [],
   "source": [
    "churn=churn[~churn[nan_columns].isnull().all(axis=1)]\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8ngtLTTw1ce",
    "outputId": "ce447628-b276-46bf-8065-1f70eb624cf6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# missing/nan values more than 2%\n",
    "get_nan_values(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTKMYsOsw1ch",
    "outputId": "678f832d-545e-43b1-ec31-93211f8b684d"
   },
   "outputs": [],
   "source": [
    "# Column/Features which have more than 2% missing value\n",
    "nan_columns = list(get_nan_values(2).index)\n",
    "print (nan_columns)\n",
    "\n",
    "churn[churn[nan_columns].isnull().all(axis=1)][nan_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sh09uXj9w1cj"
   },
   "source": [
    "##### drop these customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2SB9HcIw1ck",
    "outputId": "ebeb1559-942d-476c-d38e-9f49a4987b28"
   },
   "outputs": [],
   "source": [
    "churn=churn[~churn[nan_columns].isnull().all(axis=1)]\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NACoOfVTw1co"
   },
   "outputs": [],
   "source": [
    "# For other customers where we have missing values, impute them with 0. \n",
    "\n",
    "nan_columns.remove('date_of_last_rech_8')\n",
    "nan_columns.remove('date_of_last_rech_9')\n",
    "impute_nan_values(churn,nan_list=nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrHn6DAxw1cp",
    "outputId": "67adf5b3-58e7-4092-adb2-5064e43dba6c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Column/Features which have more than 0% missing values\n",
    "get_nan_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2oIZ0SAw1cu",
    "outputId": "b54c38be-4ad0-431b-a358-874b29db8558"
   },
   "outputs": [],
   "source": [
    "#Check above features\n",
    "nan_columns = ['loc_og_t2o_mou','std_og_t2o_mou','loc_ic_t2o_mou','last_date_of_month_7','last_date_of_month_8','last_date_of_month_9']\n",
    "for c in nan_columns:\n",
    "    print(churn[c].value_counts())\n",
    "    churn[c].fillna(churn[c].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### above features have  one value. imputing their missing values with  mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjx6oo2Yw1cy",
    "outputId": "27518364-ca39-401d-e492-afc85ce665c2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Column/Features which have more than 0% missing value\n",
    "get_nan_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VALyQ_Flw1c0",
    "outputId": "69cf94b5-ba30-4ea6-a059-99fb8b11432c"
   },
   "outputs": [],
   "source": [
    "#number of rows that has null values\n",
    "nan_columns = list(get_nan_values(0).index)\n",
    "len(churn[churn[nan_columns].isnull().all(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvljWLqHw1c3"
   },
   "outputs": [],
   "source": [
    "churn[churn['date_of_last_rech_6'].isnull()]['date_of_last_rech_6'] = '6/30/2014'\n",
    "churn[churn['date_of_last_rech_7'].isnull()]['date_of_last_rech_7'] = '7/31/2014'\n",
    "churn[churn['date_of_last_rech_8'].isnull()]['date_of_last_rech_8'] = '8/31/2014'\n",
    "churn[churn['date_of_last_rech_9'].isnull()]['date_of_last_rech_9'] = '9/30/2014'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctJ4Mw_8w1c5"
   },
   "source": [
    "<br><br>columns with 0 (as values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vz2OPtSaw1c6",
    "outputId": "a3f86eef-ff61-492d-e8ae-b46eec0edd8b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zero_columns=churn.columns[(churn == 0).all()]\n",
    "zero_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQWFI3V7w1c9"
   },
   "outputs": [],
   "source": [
    "# drop columns which have single value '0'. \n",
    "churn.drop(zero_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RIOWKmcw1c-",
    "outputId": "6bc3abf4-6c90-49a6-cd37-02b4235e1bbb"
   },
   "outputs": [],
   "source": [
    "# Percentage of data after Data cleaning.\n",
    "print(\"after Data cleaning :% of data {}%\".format(round(churn.shape[0]/99999 *100,2)))\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjw-a_hEw1dB"
   },
   "source": [
    "##### check  data types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ETZnE1_w1dD",
    "outputId": "d4abac5e-2576-4f43-9190-8ee49448704c"
   },
   "outputs": [],
   "source": [
    "churn.reset_index(inplace=True,drop=True)\n",
    "# date columns filter\n",
    "date_columns = list(churn.filter(regex='date').columns)\n",
    "date_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuClA7HUw1dF"
   },
   "outputs": [],
   "source": [
    "# Converting dtype of date columns to datetime\n",
    "for col in date_columns:\n",
    "    churn[col] = pd.to_datetime(churn[col], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54YP75GUw1dH",
    "outputId": "66008bd4-5815-4b5b-825f-44445c8e2889"
   },
   "outputs": [],
   "source": [
    "churn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uzhtu1KKw1dL"
   },
   "source": [
    "##### monthly features which are not in the standard naming (\\_6,\\_7,\\_8,\\_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cN2FCQ0iw1dN"
   },
   "outputs": [],
   "source": [
    "# renaming columns,\n",
    "#'jun_vbc_3g' : 'jun_vbc_3g_6'\n",
    "#'jul_vbc_3g' : 'july_vbc_3g_7'\n",
    "#'aug_vbc_3g' : 'aug_vbc_3g_8'\n",
    "#'sep_vbc_3g' : 'sep_vbc_3g_9'\n",
    "churn.rename(columns={'jun_vbc_3g' : 'jun_vbc_3g_6', 'jul_vbc_3g' : 'july_vbc_3g_7', 'aug_vbc_3g' : 'aug_vbc_3g_8',\n",
    "                      'sep_vbc_3g' : 'sep_vbc_3g_9'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0pyAEUgqw1dS"
   },
   "source": [
    "**Derived Variables for** 'vol_data_mb_6', 'vol_data_mb_7', 'vol_data_mb_8', 'vol_data_mb_9'\n",
    "\n",
    "These will store the total data volume (= vol_2g_mb_* + vol_3g_mb_*) monthwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rg_rkfalw1dT"
   },
   "outputs": [],
   "source": [
    "#Derived Variables for: 'vol_data_mb_6', 'vol_data_mb_7', 'vol_data_mb_8', 'vol_data_mb_9',\n",
    "for i in range(6,10):\n",
    "    churn['vol_data_mb_'+str(i)] = (churn['vol_2g_mb_'+str(i)]+churn['vol_3g_mb_'+str(i)]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrjIoPLqw1dV"
   },
   "source": [
    "###### Filter high-value customers\n",
    "upto 70th percentile of the average recharge amount in the first two months ( good phase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s48O0Cchw1dW",
    "outputId": "d928f40c-f839-4874-c815-ee65db769918"
   },
   "outputs": [],
   "source": [
    "recharge_col = churn.filter(regex=('count')).columns\n",
    "churn[recharge_col].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OYxyezxw1da"
   },
   "source": [
    "**Derived Variables for** avg_rech_amt_6,avg_rech_amt_7,avg_rech_amt_8,avg_rech_amt_9\n",
    "##### average recharge value month wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SrlH8Cktw1db"
   },
   "outputs": [],
   "source": [
    "# Derived Variables for: avg_rech_amt_6,avg_rech_amt_7,avg_rech_amt_8,avg_rech_amt_9\n",
    "for i in range(6,10):\n",
    "    churn['avg_rech_amt_'+str(i)] = round(churn['total_rech_amt_'+str(i)]/churn['total_rech_num_'+str(i)]+1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5N3thOfow1de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "impute_nan_values(churn,nan_list=['avg_rech_amt_6','avg_rech_amt_7','avg_rech_amt_8','avg_rech_amt_9'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SnL_dQ01w1df"
   },
   "source": [
    "**Derived Variables for** total_rech_num_data_6,total_rech_num_data_7,total_rech_num_data_8,total_rech_num_data_9\n",
    "\n",
    "##### total number of data recharge month wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emHL6dAMw1dg"
   },
   "outputs": [],
   "source": [
    "#Derived Variables for total_rech_num_data_6,total_rech_num_data_7,total_rech_num_data_8,total_rech_num_data_9\n",
    "for i in range(6,10):\n",
    "    churn['total_rech_num_data_'+str(i)] = (churn['count_rech_2g_'+str(i)]+churn['count_rech_3g_'+str(i)]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OocpanW-w1di"
   },
   "source": [
    "**Derived Variables for** total_rech_amt_data_6,total_rech_amt_data_7,total_rech_amt_data_8,total_rech_amt_data_9\n",
    "##### total amount of data recharge month wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rX-9PquQw1dj"
   },
   "outputs": [],
   "source": [
    "#Derived Variables for total_rech_amt_data_6,total_rech_amt_data_7,total_rech_amt_data_8,total_rech_amt_data_9\n",
    "for i in range(6,10):\n",
    "    churn['total_rech_amt_data_'+str(i)] = churn['total_rech_num_data_'+str(i)]*churn['av_rech_amt_data_'+str(i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CQ3LlH7_w1dk"
   },
   "source": [
    "**Derived Variables for** total_month_rech_6,total_month_rech_7,total_month_rech_8,total_month_rech_9\n",
    "\n",
    "##### total recharge amount month wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgZIynXMw1dm",
    "outputId": "1f52cdee-6c2d-4d89-ddb6-d1c73e6cd72a"
   },
   "outputs": [],
   "source": [
    "#Derived Variables for total_mon_rech_6,total_mon_rech_7,total_mon_rech_8,total_mon_rech_9\n",
    "for i in range(6,10):\n",
    "    churn['total_month_rech_'+str(i)] = churn['total_rech_amt_'+str(i)]+churn['total_rech_amt_data_'+str(i)]\n",
    "churn.filter(regex=('total_month_rech')).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SXsOuKsw1dp",
    "outputId": "32ab1994-0eef-4104-a3e3-d67af23e7adf"
   },
   "outputs": [],
   "source": [
    "# calculate avegare of first two months (good phase) total monthly recharge amount\n",
    "good_phase =(churn.total_month_rech_6 + churn.total_month_rech_7)/2\n",
    "# calculate cutoff which is the 70th percentile of the good phase average recharge amounts\n",
    "highvalue_cutoff= np.percentile(good_phase,70)\n",
    "# users who has avg. recharge amount >= to the cutoff of 70th percentile.\n",
    "highvalue_users = churn[good_phase >=  highvalue_cutoff]\n",
    "highvalue_users.reset_index(inplace=True,drop=True)\n",
    "\n",
    "print(\"No. of High-Value Customers: %d\\n\"% len(highvalue_users))\n",
    "print(\"% of High-value users : {}%\".format(round(len(highvalue_users)/churn.shape[0]*100),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tNPxDUQ7w1ds"
   },
   "source": [
    "###### Tagging Churners\n",
    "Now tag the churned customers (churn=1, else 0) based on the fourth month as follows:\n",
    "\n",
    "Those who have not made any calls (either incoming or outgoing) AND have not used mobile internet even once in the churn phase. The attributes we need to use to tag churners are:\n",
    "- total_ic_mou_9\n",
    "- total_og_mou_9\n",
    "- vol_2g_mb_9\n",
    "- vol_3g_mb_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find out churn status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhHhvVILw1du"
   },
   "outputs": [],
   "source": [
    "def churn_status(data,churn_phase=9):\n",
    "    #argument: churn_phase,4th month number in which users churn (default= 9)\n",
    "    churn_var= ['vol_2g_mb_','vol_3g_mb_','total_ic_mou_','total_og_mou_']\n",
    "    isChurn = ~data[[s + str(churn_phase) for s in churn_var ]].any(axis=1)\n",
    "    isChurn = isChurn.map({True:1, False:0})\n",
    "    return isChurn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0diq7zy2w1dx",
    "outputId": "41032039-62bb-4f8a-e4aa-0243b3ae7ebe"
   },
   "outputs": [],
   "source": [
    "highvalue_users['churn'] = churn_status(highvalue_users,9)\n",
    "print(\" {} users tagged as churners out of {} High-Value Customers.\".format(len(highvalue_users[highvalue_users.churn == 1]),highvalue_users.shape[0]))\n",
    "print(\"High-value Customer Churn Percentage : {}%\".format(round(len(highvalue_users[highvalue_users.churn == 1])/highvalue_users.shape[0] *100,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLsZKd11w1dz"
   },
   "source": [
    "Here we have **highly imbalanced** data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFQpGLvaw1d0"
   },
   "source": [
    "---\n",
    "##  Data Analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQKORwbXw1d1"
   },
   "source": [
    "##### function to plot histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjdRs2oYw1d1"
   },
   "outputs": [],
   "source": [
    "# Function to plot the histogram with labels\n",
    "def plot_hist(dataset,col,binsize):\n",
    "    fig, ax = plt.subplots(figsize=(20,4))\n",
    "    counts, bins, patches = ax.hist(dataset[col],bins=range(0,dataset[col].max(),round(binsize)), facecolor='yellow', edgecolor='red')\n",
    "    \n",
    "    # Set the ticks to be at the edges of the bins.\n",
    "    ax.set_xticks(bins)\n",
    "    bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "    for count, x in zip(counts, bin_centers):\n",
    "        # Label\n",
    "        percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "        ax.annotate(percent, xy=(x,0.2), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -32), textcoords='offset points', va='top', ha='center')\n",
    "    \n",
    "    ax.set_xlabel(col.upper())\n",
    "    ax.set_ylabel('Count')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to calculate monthly avg calls and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9TdcYbRw1d3"
   },
   "outputs": [],
   "source": [
    "def plot_avgMonthlyCalls(pltType,data,calltype,colList):\n",
    "    # style\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    # create a color palette\n",
    "    palette = plt.get_cmap('Set1')\n",
    "    \n",
    "    if pltType == 'multi':\n",
    "        #Create dataframe after grouping on AON with colList features\n",
    "        total_call_mou = pd.DataFrame(data.groupby('aon_bin',as_index=False)[colList].mean())\n",
    "        total_call_mou['aon_bin']=pd.to_numeric(total_call_mou['aon_bin'])\n",
    "        total_call_mou\n",
    "        # multiple line plot\n",
    "        num=0\n",
    "        fig, ax = plt.subplots(figsize=(15,8))\n",
    "        for column in total_call_mou.drop('aon_bin', axis=1):\n",
    "            num+=1\n",
    "            ax.plot(total_call_mou['aon_bin'] , total_call_mou[column], marker='', color=palette(num), linewidth=2, alpha=0.9, label=column)\n",
    "         \n",
    "        ## Add legend\n",
    "        plt.legend(loc=2, ncol=2)\n",
    "        ax.set_xticks(total_call_mou['aon_bin'])\n",
    "        \n",
    "        # Add titles\n",
    "        plt.title(\"Avg.Monthly \"+calltype+\" MOU  V/S AON\", loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "        plt.xlabel(\"Aon (years)\")\n",
    "        plt.ylabel(\"Avg. Monthly \"+calltype+\" MOU\")\n",
    "    elif pltType == 'single':\n",
    "        fig, ax = plt.subplots(figsize=(8,4))\n",
    "        ax.plot(data[colList].mean())\n",
    "        ax.set_xticklabels(['Jun','Jul','Aug','Sep'])\n",
    "        \n",
    "        # Add titles\n",
    "        plt.title(\"Avg. \"+calltype+\" MOU  V/S Month\", loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "        plt.xlabel(\"Month\")\n",
    "        plt.ylabel(\"Avg. \"+calltype+\" MOU\")\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to plot churn by mou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLOa5t68w1d5"
   },
   "outputs": [],
   "source": [
    "def plot_byChurnMou(colList,calltype):\n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "    df=highvalue_users.groupby(['churn'])[colList].mean().T\n",
    "    plt.plot(df)\n",
    "    ax.set_xticklabels(['Jun','Jul','Aug','Sep'])\n",
    "    ## Add legend\n",
    "    plt.legend(['Non-Churn', 'Churn'])\n",
    "    # Add titles\n",
    "    plt.title(\"Avg. \"+calltype+\" MOU  V/S Month\", loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Avg. \"+calltype+\" MOU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### function to plot by churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8gag9qdw1d6"
   },
   "outputs": [],
   "source": [
    "def plot_byChurn(data,col):\n",
    "    # per month churn vs Non-Churn\n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "    colList=list(data.filter(regex=(col)).columns)\n",
    "    colList = colList[:3]\n",
    "    plt.plot(highvalue_users.groupby('churn')[colList].mean().T)\n",
    "    ax.set_xticklabels(['Jun','Jul','Aug','Sep'])\n",
    "    ## Add legend\n",
    "    plt.legend(['Non-Churn', 'Churn'])\n",
    "    # Add titles\n",
    "    plt.title( str(col) +\" V/S Month\", loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(col)\n",
    "    plt.show()\n",
    "    # Numeric stats for per month churn vs Non-Churn\n",
    "    return highvalue_users.groupby('churn')[colList].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxYP-q7Sw1d8",
    "outputId": "e917d710-5969-43bf-bcd2-cd0e58cdd8db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering the common monthly columns\n",
    "common_cols = highvalue_users.filter(regex ='_6').columns\n",
    "monthly_cols = [item.strip('_6') for item in common_cols]\n",
    "monthly_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWH3yH1Iw1d-",
    "outputId": "23f5d9c1-8b3d-4881-a790-c7b8f5b1f968",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# getting the number of monthly columns and profile columns\n",
    "print (\"columns:\", highvalue_users.shape[1] )\n",
    "print (\"monthly columns : \",len(monthly_cols))\n",
    "print (\"Total monthly columns phase wise (%d*4): %d\"%(len(monthly_cols), len(monthly_cols) * 4))\n",
    "print (\"Columns other than monthly columns :\", highvalue_users.shape[1] - (len(monthly_cols) * 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8h7FoRMzw1eB"
   },
   "outputs": [],
   "source": [
    "#  remove all the attributes corresponding to the churn phase (all attributes having ‘ _9’, etc. in their names).\n",
    "attr_9List = highvalue_users.filter(regex=('_9')).columns\n",
    "highvalue_users.drop(attr_9List,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x0J7mTEYw1eF",
    "outputId": "37c73aca-a4b7-459d-d016-72cdc0c53b63",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list of monthly columns 6,7,8\n",
    "monthly_cols = [x + s for s in ['_6','_7','_8'] for x in monthly_cols]\n",
    "monthly_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oKXiNmSbw1eH",
    "outputId": "08e883eb-4ef4-496d-e7bc-f328eb32b679"
   },
   "outputs": [],
   "source": [
    "# columns which are not monthly columns\n",
    "nonmonthly_cols = [col for col in highvalue_users.columns if col not in monthly_cols]\n",
    "nonmonthly_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YQFLTeVw1eK"
   },
   "source": [
    "###### Feature: circle_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RY0OWTDLw1eK",
    "outputId": "69eaad65-a1b4-4561-fcc0-ba1339d8e311"
   },
   "outputs": [],
   "source": [
    "# Getting  distinct circle_id's\n",
    "highvalue_users.circle_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_1PgbT4w1eN"
   },
   "source": [
    "We can drop this feature since it has only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ag1zWjQFw1eN"
   },
   "outputs": [],
   "source": [
    "highvalue_users.drop('circle_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f73KSgqJw1eP"
   },
   "source": [
    "###### Feature: aon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qVLacWZw1eR",
    "outputId": "41181225-eba8-4b50-e659-af312bcb536d"
   },
   "outputs": [],
   "source": [
    "# Customers distribution by age \n",
    "plot_hist(highvalue_users,'aon',365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOgSziUgw1eU"
   },
   "source": [
    "- **Minimun Age** on network is 180 days.\n",
    "- **Average age** on network for customers is 1200 days (3.2 years).\n",
    "- 27% of the **High Value users are in their 2nd year** with the network.\n",
    "- Almost 71% users have Age on network **less than 4 years.**\n",
    "- 15% users are with the network from **over 7 years.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlWZlssNw1eV"
   },
   "outputs": [],
   "source": [
    "#Create Derived categorical variable\n",
    "highvalue_users['aon_bin'] = pd.cut(churn['aon'], range(0,churn['aon'].max(),365), labels=range(0,int(round(churn['aon'].max()/365))-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwaq2WOww1eW"
   },
   "source": [
    "###### Incoming VS month VS AON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUHlpHBZw1eX",
    "outputId": "9937fe97-1833-4dfb-dda4-6007f4e43dc4"
   },
   "outputs": [],
   "source": [
    "# Plotting Avg. total monthly incoming MOU vs AON\n",
    "incoming_columns = highvalue_users.filter(regex ='total_ic_mou').columns\n",
    "plot_avgMonthlyCalls('single',highvalue_users,calltype='incoming',colList=incoming_columns)\n",
    "plot_avgMonthlyCalls('multi',highvalue_users,calltype='incoming',colList=incoming_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxzrjh6Kw1ea"
   },
   "source": [
    "Above plot shows that\n",
    "- The more a customer stays on with the operator(AON), more the total monthly incoming MOU.\n",
    "- Total Incoming MOU avg. for Jul(_7) are more than the previous Jun(_6) for customers in all AON bands.\n",
    "- Total Incoming MOU avg. for Aug(_8) cease to increace, infact it shows a decline compared to Jul(_7).\n",
    "- Total Incoming MOU avg. for Sep(_9) is well below the first months(jun _6) avg.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wl5pKN48w1ea"
   },
   "source": [
    "###### Outgoing VS month VS AON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUszJkD2w1eb",
    "outputId": "e1e00cae-5cc3-4e17-f499-03dd735fe988"
   },
   "outputs": [],
   "source": [
    "#  Avg. total monthly outgoing MOU vs AON\n",
    "outgoing_columns = highvalue_users.filter(regex ='total_og_mou').columns\n",
    "plot_avgMonthlyCalls('single',highvalue_users,calltype='outgoing',colList=outgoing_columns)\n",
    "plot_avgMonthlyCalls('multi',highvalue_users,calltype='outgoing',colList=outgoing_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxpn3xexw1ed"
   },
   "source": [
    "Above plot shows that\n",
    "- Total Outgoing MOU avg. for Jul(_7) are more than the previous Jun(_6) for customers in all AON bands, except in the AON band between 7 - 8 years where it is almost simillar.\n",
    "- Total outgoing MOU avg. for Aug(_8) cease to increace, infact it shows a significant decline compared to Jul(_7).\n",
    "- Total outgoing MOU avg. for Sep(_9) is the lowest of all 4 months.\n",
    "- The Avg. outgoing usage reduces drastically for customers in the AON band between 7 - 8  years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-KkCPRew1ee"
   },
   "source": [
    "###### Incoming/Outgoing MOU VS Churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ad9tzMNw1ee",
    "outputId": "162f265b-b42c-416e-9da9-bd4f1732c167"
   },
   "outputs": [],
   "source": [
    "incoming_columns = ['total_ic_mou_6','total_ic_mou_7','total_ic_mou_8']\n",
    "outgoing_columns = ['total_og_mou_6','total_og_mou_7','total_og_mou_8']\n",
    "plot_byChurnMou(incoming_columns,'Incoming')\n",
    "plot_byChurnMou(outgoing_columns,'Outgoing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YpPIQCYHw1eg"
   },
   "source": [
    "It can be observed,\n",
    "- Churners Avg. Incoming/Outgoing MOU's **drops drastically after the 2nd month,Jul.**\n",
    "- While the non-churners Avg. MOU's remains consistant and stable with each month.\n",
    "- Therefore, users MOU is a key feature to predict churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7mNl0Wnw1eg"
   },
   "source": [
    "in terms of Statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zg_UGyCiw1eg",
    "outputId": "0be18e15-603e-4944-afb9-eb28e150360f"
   },
   "outputs": [],
   "source": [
    "# Avg.Incoming MOU per month churn vs Non-Churn\n",
    "highvalue_users.groupby(['churn'])['total_ic_mou_6','total_ic_mou_7','total_ic_mou_8'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTFhYfhvw1ek",
    "outputId": "f120f999-777f-4d25-dc08-d43db3b12abc"
   },
   "outputs": [],
   "source": [
    "# Avg. Outgoing MOU per month churn vs Non-Churn\n",
    "highvalue_users.groupby(['churn'])['total_og_mou_6','total_og_mou_7','total_og_mou_8'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMET-OJ3w1el"
   },
   "source": [
    "**Derived Variables:** og_to_ic_mou_6, og_to_ic_mou_7, og_to_ic_mou_8\n",
    "---->(=total_og_mou_* / total_ic_mou_*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mohKvwpw1em"
   },
   "outputs": [],
   "source": [
    "# adding 1 to denominator to avoid dividing by 0 and getting nan values.\n",
    "for i in range(6,9):\n",
    "    highvalue_users['og_to_ic_mou_'+str(i)] = (highvalue_users['total_og_mou_'+str(i)])/(highvalue_users['total_ic_mou_'+str(i)]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUBGgIHGw1en",
    "outputId": "883997f0-f8b5-493b-c995-0147153a458c"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(highvalue_users,'og_to_ic_mou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eubdG6kPw1eq"
   },
   "source": [
    "- Outgoing to incoming mou remains drops significantly for churners from month Jul(6) to Aug(7).\n",
    "- While it remains almost consistent for the non-churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3HXUxnd3w1er"
   },
   "source": [
    "##### Derived Variables:\n",
    "loc_og_to_ic_mou_6, loc_og_to_ic_mou_7, loc_og_to_ic_mou_8(=loc_og_mou_* / loc_ic_mou_*) for each month. These features will combine the local calls, both incoming and outgoing informations and should be a **better predictor of churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1U3e9bkHw1es"
   },
   "outputs": [],
   "source": [
    "# adding 1 to denominator to avoid dividing by 0 and getting nan values.\n",
    "for i in range(6,9):\n",
    "    highvalue_users['loc_og_to_ic_mou_'+str(i)] = (highvalue_users['loc_og_mou_'+str(i)])/(highvalue_users['loc_ic_mou_'+str(i)]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6cv9ZB8w1ev",
    "outputId": "671f1e6d-075f-49b9-ae6a-b5c76aa8abfe"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(highvalue_users,'loc_og_to_ic_mou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FqAf55Avw1ey"
   },
   "source": [
    "It can be observed that,\n",
    "- The local outgoing to incoming call mou ratio is genrally low for churners right from the begining of the good phase.\n",
    "- local mou pattern for the non-churners remains almost constant through out the 3 months.\n",
    "- The churners genrally show a low loc mou ratio but it drops dramatically after the 2nd month.\n",
    "- This might suggest that people who are not making/reciving much local calls during their tenure are more likely to churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kMvYzHlvw1ez"
   },
   "source": [
    "###### Total data volume VS Churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISBgmK4Ew1e0",
    "outputId": "91cad954-f998-4094-e3c3-07163a731147"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(highvalue_users,'vol_data_mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r-VlRoFYw1e2"
   },
   "source": [
    "- The volume of data mb used drops significantly for churners from month Jul(6) to Aug(7).\n",
    "- While it remains almost consistent for the non-churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_w1XwBjw1e4"
   },
   "source": [
    "###### Total monthly rech VS Churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kA7BHg4pw1e4",
    "outputId": "bf6d565c-4316-429b-aa8f-f43c17573d75"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(highvalue_users,'total_month_rech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MNVEbzYw1e7"
   },
   "source": [
    "- total monthly rech amount also drops significantly for churners from month Jul(6) to Aug(7).\n",
    "- While it remains almost consistent for the non-churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DhGGc61cw1e7"
   },
   "source": [
    "###### max_rech_amt VS Churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uvx_xVncw1e7",
    "outputId": "35a244f4-72eb-41b8-e48e-d85ca352c1d6"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(highvalue_users,'max_rech_amt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qr8ZKwCdw1e9"
   },
   "source": [
    "- maximum recharge amount also drops significantly for churners from month Jul(6) to Aug(7).\n",
    "- While it remains almost consistent for the non-churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxxptRORw1e9"
   },
   "source": [
    "###### arpu VS Churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3P2OhmWSw1e9",
    "outputId": "f4fed0f6-1249-4391-8789-296b542d7422"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(highvalue_users,'arpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CC2oHkGuw1e_"
   },
   "source": [
    "- Average revenue per user,arpu also drops significantly for churners from month Jul(6) to Aug(7).\n",
    "- While it remains almost consistent for the non-churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYESr0Aiw1e_"
   },
   "source": [
    "**Derived Variables:** Total_loc_mou_6, Total_loc_mou_7, Total_loc_mou_8<br>\n",
    " **Total MOU** (=loc_og_mou+loc_ic_mou)Month wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5OHv6J8Kw1e_"
   },
   "outputs": [],
   "source": [
    "#Create new feature: Total_loc_mou_6,Total_loc_mou_7,lTotal_loc_mou_8\n",
    "for i in range(6,9):\n",
    "    highvalue_users['Total_loc_mou_'+str(i)] = (highvalue_users['loc_og_mou_'+str(i)])+(highvalue_users['loc_ic_mou_'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1EXeBuA-w1fA",
    "outputId": "833f782f-7c77-430a-a2c7-a87a54597c89"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(highvalue_users,'Total_loc_mou_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "71GBXam5w1fC"
   },
   "source": [
    "It can be observed that,\n",
    "- The Total local call mou is genrally low for churners right from the begining of the good phase.\n",
    "- local mou pattern for the non-churners remains almost constant through out the 3 months.\n",
    "- The churners genrally show a low total loc mou but it drops dramatically after the 2nd month.\n",
    "- This might suggest that people who are not making/reciving much local calls during their tenure are more likely to churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3323CYvCw1fC"
   },
   "source": [
    "**Derived Variables:** Total_roam_mou_6,Total_roam_mou_7,Total_roam_mou_8<br>\n",
    "**Total roaming MOU** (=roam_ic_mou+roam_og_mou) month wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rz2Tf5bVw1fC"
   },
   "outputs": [],
   "source": [
    "#Create new feature: Total_roam_mou_6,Total_roam_mou_7,Total_roam_mou_8\n",
    "for i in range(6,9):\n",
    "    highvalue_users['Total_roam_mou_'+str(i)] = (highvalue_users['roam_ic_mou_'+str(i)])+(highvalue_users['roam_og_mou_'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1OXqg8LHw1fE",
    "outputId": "52f4d169-17c5-444b-b0fc-58a7a8dd4087"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(highvalue_users,'Total_roam_mou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNc3fdPAw1fF"
   },
   "source": [
    "It can be observed that,\n",
    "- Surprisingly, the roaming usage of churners is way higher than those of non-churners across all months\n",
    "- People who are making/reciving more roaming calls during their tenure are more likely to churn.\n",
    "- This might suggest that the operators roaming tariffs are higher than what are offered by its competitor, thus forming one of the reasons of churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wch0B-XNw1fG"
   },
   "source": [
    "###### last_day_rch_amt VS Churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fB7WAP5xw1fG",
    "outputId": "6d6134da-cba4-426d-850e-662ef0fc9cc4"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(highvalue_users,'last_day_rch_amt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a400Ib-fw1fH"
   },
   "source": [
    "- The avg. last recharge amount for churners is less than half the amount of that of the non-churners.\n",
    "- Suggesting, as the recharge amount reduces for a customer its chances to churn increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yenNQmIHw1fI"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1hakLJ3Tw1fJ"
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to plot roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3TbLJ8tw1fK"
   },
   "outputs": [],
   "source": [
    "def plot_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to get Model Metrics Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DSqyqoQw1fM"
   },
   "outputs": [],
   "source": [
    "def getModelMetricsResults(actual_churn=False,pred_churn=False):\n",
    "\n",
    "    confusion = metrics.confusion_matrix(actual_churn, pred_churn)\n",
    "\n",
    "    TP = confusion[1,1] # true positive \n",
    "    TN = confusion[0,0] # true negatives\n",
    "    FP = confusion[0,1] # false positives\n",
    "    FN = confusion[1,0] # false negatives\n",
    "\n",
    "    print(\"Roc_auc_score : {}\".format(metrics.roc_auc_score(actual_churn,pred_churn)))\n",
    "    # Let's see the sensitivity of our logistic regression model\n",
    "    print('Sensitivity/Recall : {}'.format(TP / float(TP+FN)))\n",
    "    # Let us calculate specificity\n",
    "    print('Specificity: {}'.format(TN / float(TN+FP)))\n",
    "    # Calculate false postive rate - predicting churn when customer does not have churned\n",
    "    print('False Positive Rate: {}'.format(FP/ float(TN+FP)))\n",
    "    # positive predictive value \n",
    "    print('Positive predictive value: {}'.format(TP / float(TP+FP)))\n",
    "    # Negative predictive value\n",
    "    print('Negative Predictive value: {}'.format(TN / float(TN+ FN)))\n",
    "    # sklearn precision score value \n",
    "    print('sklearn precision score value: {}'.format(metrics.precision_score(actual_churn, pred_churn )))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to predict churning with probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6BgW8zhw1fN"
   },
   "outputs": [],
   "source": [
    "def predictChurnUsingProbCutOff(model,X,y,prob):\n",
    "    # Funtion to predict the churn using the input probability cut-off\n",
    "    # Input arguments: model instance, x and y to predict using model and cut-off probability\n",
    "    \n",
    "    # predict\n",
    "    pred_probs = model.predict_proba(X)[:,1]\n",
    "    \n",
    "    y_df= pd.DataFrame({'churn':y, 'churn_Prob':pred_probs})\n",
    "    # Creating new column 'predicted' with 1 if Churn_Prob>0.5 else 0\n",
    "    y_df['final_predicted'] = y_df.churn_Prob.map( lambda x: 1 if x > prob else 0)\n",
    "    # Let's see the head\n",
    "    getModelMetricsResults(y_df.churn,y_df.final_predicted)\n",
    "    return y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fE8Fneyow1fO"
   },
   "outputs": [],
   "source": [
    "def findOptimalCutoff(df):\n",
    "    #Function to find the optimal cutoff for classifing as churn/non-churn\n",
    "    # Let's create columns with different probability cutoffs \n",
    "    numbers = [float(x)/10 for x in range(10)]\n",
    "    for i in numbers:\n",
    "        df[i] = df.churn_Prob.map( lambda x: 1 if x > i else 0)\n",
    "    #print(df.head())\n",
    "    \n",
    "    # Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "    cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    # TP = confusion[1,1] # true positive \n",
    "    # TN = confusion[0,0] # true negatives\n",
    "    # FP = confusion[0,1] # false positives\n",
    "    # FN = confusion[1,0] # false negatives\n",
    "    \n",
    "    num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "    for i in num:\n",
    "        cm1 = metrics.confusion_matrix(df.churn, df[i] )\n",
    "        total1=sum(sum(cm1))\n",
    "        accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "        \n",
    "        speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "        sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "        cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "    print(cutoff_df)\n",
    "    # Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "    cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rEgMZIkQw1fP"
   },
   "outputs": [],
   "source": [
    "def fit_model(alg, X_train, y_train, performCV=True, cv_folds=5):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_train)\n",
    "    dtrain_predprob = alg.predict_proba(X_train)[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, X_train, y_train, cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.roc_auc_score(y_train, dtrain_predictions))\n",
    "    print (\"Recall/Sensitivity : %.4g\" % metrics.recall_score(y_train, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iXvYnp8uw1fQ"
   },
   "outputs": [],
   "source": [
    "# creating copy of the final hv_user dataframe\n",
    "highvalue_users_PCA = highvalue_users.copy()\n",
    "# removing the columns not required for modeling\n",
    "highvalue_users_PCA.drop(['mobile_number', 'aon_bin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jW9k6Csqw1fR",
    "outputId": "b96227de-f63c-4526-e752-44024f974ce0"
   },
   "outputs": [],
   "source": [
    "# removing the datatime columns before PCA\n",
    "dateTimeCols = list(highvalue_users_PCA.select_dtypes(include=['datetime64']).columns)\n",
    "print(dateTimeCols)\n",
    "highvalue_users_PCA.drop(dateTimeCols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAPhWaMSw1fS"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#putting features variables in X\n",
    "X = highvalue_users_PCA.drop(['churn'], axis=1)\n",
    "\n",
    "#putting response variables in Y\n",
    "y = highvalue_users_PCA['churn']    \n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z--kUh-iw1fT"
   },
   "outputs": [],
   "source": [
    "#Rescaling the features before PCA as it is sensitive to the scales of the features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2f_rpgxBw1fV"
   },
   "outputs": [],
   "source": [
    "# fitting and transforming the scaler on train\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# transforming the train using the already fit scaler\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SkIe1eD0w1fW"
   },
   "source": [
    "### Handling imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q4uGI0Huw1fW"
   },
   "source": [
    "Standard classifier algorithms like Decision Tree and Logistic have Regression have a bias towards classes which have number of instances,all tends to only predict the majority class data,there is a high probability of misclassification of the minority class as compared to the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mgs0KgEow1fX"
   },
   "source": [
    "##### Synthetic Minority Over-sampling Technique\n",
    "\n",
    "A subset of data is taken from the minority class as an example and then new synthetic similar instances are created. These synthetic instances are then added to the original dataset. \n",
    "\n",
    "The new dataset is used as a sample to train the classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rBksqpD9w1fY",
    "outputId": "be2eb3e5-8361-4d03-fc9b-bc279346b9da"
   },
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "print(\"Before OverSampling, churn event rate : {}% \\n\".format(round(sum(y_train==1)/len(y_train)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UV-UfJeXw1fa"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=12, ratio = 1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A9M3hofiw1fb",
    "outputId": "fedbc2e6-0954-44e4-e1d9-8abe0ea110a6"
   },
   "outputs": [],
   "source": [
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "print(\"After OverSampling, churn event rate : {}% \\n\".format(round(sum(y_train_res==1)/len(y_train_res)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b__lZfLhw1fd"
   },
   "outputs": [],
   "source": [
    "#Improting the PCA module\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(svd_solver='randomized', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQ1FFsOhw1fe",
    "outputId": "79bc92dc-31fb-4795-c878-693bcf72c21f"
   },
   "outputs": [],
   "source": [
    "#Doing the PCA on the train data\n",
    "pca.fit(X_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STcH9AhQw1fh"
   },
   "source": [
    "we'll let PCA select the number of components basen on a variance cutoff we provide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3KZkNluIw1fn"
   },
   "source": [
    " **screeplot to assess the number of needed principal components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KhM_cr5hw1fn",
    "outputId": "bd7368f1-7df8-4142-b542-cb292359ab91",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2OwZ4EFw1fo",
    "outputId": "574e10dd-1b81-4cf4-b431-3a54c0eeffc0"
   },
   "outputs": [],
   "source": [
    "#Making the screeplot - plotting the cumulative variance against the number of components\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udrcPf5Iw1fq"
   },
   "source": [
    "##### **50 components are enough to describe 95% of the variance in the dataset**\n",
    "- We'll take 50 components for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHZTR_stw1fr"
   },
   "outputs": [],
   "source": [
    "#Using incremental PCA for efficiency - saves a lot of time on larger datasets\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "pca_final = IncrementalPCA(n_components=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2yX4W7Ow1fs",
    "outputId": "bbcc3541-5a9d-4166-ac9b-6ef4617f7132"
   },
   "outputs": [],
   "source": [
    "X_train_pca = pca_final.fit_transform(X_train_res)\n",
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FpTK1PQgw1ft",
    "outputId": "f89e0c4e-3c48-4998-c956-71a9425940f8"
   },
   "outputs": [],
   "source": [
    "#creating correlation matrix for the principal components\n",
    "corrmat = np.corrcoef(X_train_pca.transpose())\n",
    "# 1s -> 0s in diagonals\n",
    "corrmat_nodiag = corrmat - np.diagflat(corrmat.diagonal())\n",
    "print(\"max corr:\",corrmat_nodiag.max(), \", min corr: \", corrmat_nodiag.min(),)\n",
    "# we see that correlations are indeed very close to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19FTPt1zw1fu"
   },
   "source": [
    "there is no correlation between any two components, We  have almost removed multicollinearity here , and models will be more stable now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Nunv3tRw1fu",
    "outputId": "78522773-89de-4a36-cbb1-0588ac55b635"
   },
   "outputs": [],
   "source": [
    "#Applying selected components to the test data - 50 components\n",
    "X_test_pca = pca_final.transform(X_test)\n",
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FmCzPcnsxHDw"
   },
   "source": [
    "For prediction of churned customers we will be fitting variety of models,these are-\n",
    "    1. Logistic Regression\n",
    "    2. Decision Tree\n",
    "    3. Random Forest\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddW2stNaw1fy"
   },
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYSQFnDNw1fy"
   },
   "source": [
    "##### Applying Logistic Regression on  principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74Z1Hy6lw1f2"
   },
   "outputs": [],
   "source": [
    "#Training the model on the train data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "lr0 = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ShmQYRQHw1f3",
    "outputId": "183b3d74-a4c9-4633-e056-de85aeb26f4a"
   },
   "outputs": [],
   "source": [
    "fit_model(lr0, X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BIHEyLTw1f4",
    "outputId": "deb2896c-9c5e-4a6e-a4ec-9c2b69885c5e"
   },
   "outputs": [],
   "source": [
    "# Test  data Results:\n",
    "pred_probs_test = lr0.predict(X_test_pca)\n",
    "getModelMetricsResults(y_test,pred_probs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZE9bMymJw1f5",
    "outputId": "6e0b2a95-ff17-450a-c296-ce802ab615ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(y_test,pred_probs_test)))\n",
    "print(\"Recall : {}\".format(metrics.recall_score(y_test,pred_probs_test)))\n",
    "print(\"Precision : {}\".format(metrics.precision_score(y_test,pred_probs_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTSmumobw1f8",
    "outputId": "0b106229-6acd-4b18-f256-531d7d7a1cda"
   },
   "outputs": [],
   "source": [
    "#Making prediction on the test data\n",
    "pred_probs_train = lr0.predict_proba(X_train_pca)[:,1]\n",
    "print(\"roc_auc_score(Train) {:2.2}\".format(metrics.roc_auc_score(y_train_res, pred_probs_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Two0-tttw1gE",
    "outputId": "da74791b-06c9-4c89-c17c-9dd3d96b43f1"
   },
   "outputs": [],
   "source": [
    "cut_off_prob=0.5\n",
    "y_train_df = predictChurnUsingProbCutOff(lr0,X_train_pca,y_train_res,cut_off_prob)\n",
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdBWN_GKw1gG"
   },
   "source": [
    "**ROC Curve :**\n",
    "An ROC curve states that:-\n",
    "- It shows the tradeoff between sensitivity and specificity.\n",
    "- The closer the curve follows the left-hand border and then the top border of the ROC space,the test becomes more accurate\n",
    "- The closer the curve comes to the 45-degree diagonal of the ROC space,test becomes less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KM_E4-ffw1gG",
    "outputId": "f0fc2c14-3980-4f31-e901-b91ad0efb40d"
   },
   "outputs": [],
   "source": [
    "plot_roc(y_train_df.churn, y_train_df.final_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaExGch_w1gI"
   },
   "source": [
    "The roc curve is lying in the top left corner which is a sign of a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MmIrkX9w1gJ",
    "outputId": "fce7e14b-6611-434e-8863-7dd60ffe988f"
   },
   "outputs": [],
   "source": [
    "#plot_roc(y_pred_final.Churn, y_pred_final.predicted)\n",
    "print(\"roc_auc_score : {:2.2f}\".format(metrics.roc_auc_score(y_train_df.churn, y_train_df.final_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8O9FgFaw1gL"
   },
   "source": [
    "**Optimal Cutoff Point**<br>\n",
    "Since recall or sensitivity is a much more important metrics for churn prediction. A trade off between sensitivity(or recall) and specificity is to be consideredfor the same . We will try adjusting the probability cut offs which will result into higher sensitivity or recall rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kf3tderOw1gL",
    "outputId": "f91ef123-1b47-4a35-98d3-f978bd087bc8"
   },
   "outputs": [],
   "source": [
    "# sensitivity vs specificity trade-off\n",
    "findOptimalCutoff(y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o7WGRV_Hw1gN"
   },
   "source": [
    "#### **From the curve above, 0.45 is the optimum point .**\n",
    "cutoff between 0.4 and 0.6 can also be taken but to keep the test sensitivity/recall significant ,here we can take 0.45. At this point there is a balance of sensitivity, specificity and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRv0BqTVw1gN",
    "outputId": "3d3fcb39-cc39-46c8-dd8b-959ba24096ec"
   },
   "outputs": [],
   "source": [
    "# predicting with the choosen cut-off on train\n",
    "cut_off_prob = 0.45\n",
    "predictChurnUsingProbCutOff(lr0,X_train_pca,y_train_res,cut_off_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Go7Fnixw1gO"
   },
   "source": [
    "**Making prediction on test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKY1YYVow1gP",
    "outputId": "4a4cccd7-3dd5-4999-e99e-74ae98b20837"
   },
   "outputs": [],
   "source": [
    "# predicting with the choosen cut-off on test\n",
    "predictChurnUsingProbCutOff(lr0,X_test_pca,y_test,cut_off_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQiUjiQcw1gQ"
   },
   "source": [
    "The resulting model, after PCA and logistic regression (with optimal cutoff setting) on the train and test set.\n",
    "- **train sensitivity  :** 86.47%, **train roc auc score  :** 82.1%\n",
    "- **test sensitivity   :** 84.40%, **test roc auc score  :** 81.21%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wUZpKshPw1gQ"
   },
   "source": [
    "### 2. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFFPJTG4w1gQ"
   },
   "source": [
    "##### Applying Decision Tree Classifier on our principal components with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H1-91gmhw1gQ",
    "outputId": "21c074ac-4a82-495a-8197-9c656f2fdb46"
   },
   "outputs": [],
   "source": [
    "dt0 = DecisionTreeClassifier(class_weight='balanced',\n",
    "                             max_features='auto',\n",
    "                             min_samples_split=100,\n",
    "                             min_samples_leaf=100,\n",
    "                             max_depth=6,\n",
    "                             random_state=10)\n",
    "fit_model(dt0, X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DMvsTkDMw1gT",
    "outputId": "6e435fdc-0611-4c01-87b6-3ee28085d116"
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred_probs_test = dt0.predict(X_test_pca)\n",
    "#Let's check the model metrices.\n",
    "getModelMetricsResults(actual_churn=y_test,pred_churn=pred_probs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pj9OcaFew1gU"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': range(5,15,3),\n",
    "    'min_samples_leaf': range(100, 400, 50),\n",
    "    'min_samples_split': range(100, 400, 100),\n",
    "    'max_features': [8,10,15]\n",
    "}\n",
    "# Create a based model\n",
    "dt = DecisionTreeClassifier(class_weight='balanced',random_state=10)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = dt, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = 4,verbose = 1,scoring=\"f1_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy13PLucw1gV",
    "outputId": "1f0378de-25be-42e3-f2af-a2190c3ecc7c"
   },
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UX48ntdqw1gW",
    "outputId": "0d97e677-7869-45b3-e44a-5dd79f5faf82"
   },
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('recall of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byVSAxvww1gZ"
   },
   "outputs": [],
   "source": [
    "# model with the best hyperparameters\n",
    "dt_final = DecisionTreeClassifier(class_weight='balanced',\n",
    "                             max_depth=14,\n",
    "                             min_samples_leaf=100, \n",
    "                             min_samples_split=100,\n",
    "                             max_features=15,\n",
    "                             random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B3APjfT9w1ga",
    "outputId": "d9f12dac-a2b1-4f62-b2ba-98d88287691d"
   },
   "outputs": [],
   "source": [
    "fit_model(dt_final,X_train_pca,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6aY4FBcw1gb",
    "outputId": "c74cb7d6-1dd5-4c6f-f503-a7d3d5272a84"
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred_probs_test = dt_final.predict(X_test_pca)\n",
    "#Let's check the model metrices.\n",
    "getModelMetricsResults(actual_churn=y_test,pred_churn=pred_probs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBXXQxNpw1gc",
    "outputId": "ee5f5e32-073d-4f7c-ee21-c1c2882599ef"
   },
   "outputs": [],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test,pred_probs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6kYp9A-qw1ge"
   },
   "source": [
    "##### Recall rate by deciding an optimal cut-off for the model to predict churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvdGqTxaw1gf",
    "outputId": "76e54361-7816-44ae-ba50-b506bdbfbe5d"
   },
   "outputs": [],
   "source": [
    "# predicting churn with default cut-off 0.5\n",
    "cut_off_prob = 0.5\n",
    "y_train_df = predictChurnUsingProbCutOff(dt_final,X_train_pca,y_train_res,cut_off_prob)\n",
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i38pLQJOw1gj",
    "outputId": "1a2eec91-0040-4ae5-e45b-10cde227adb5"
   },
   "outputs": [],
   "source": [
    "# finding cut-off with the right balance of the metrices\n",
    "findOptimalCutoff(y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ztxqIP5Yw1gl"
   },
   "source": [
    "**From the curve above, let'choose 0.4 as the optimum point to make a high enough sensitivity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nr_3qhjrw1gm",
    "outputId": "ba3fc6df-7e7c-424b-c79b-2137e836764f"
   },
   "outputs": [],
   "source": [
    "# predicting churn with cut-off 0.4\n",
    "cut_off_prob=0.4\n",
    "y_train_df = predictChurnUsingProbCutOff(dt_final,X_train_pca,y_train_res,cut_off_prob)\n",
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GvmbpdC9w1gp"
   },
   "source": [
    "- At 0.58 cut-off prob. there is a balance of sensitivity , specificity and accuracy.\n",
    "<br>Lets see how it performs on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XF5NfQfUw1gp",
    "outputId": "5d0231fa-3456-4381-9ad4-c2de619f04c4"
   },
   "outputs": [],
   "source": [
    "#Test data Results\n",
    "y_test_df= predictChurnUsingProbCutOff(dt_final,X_test_pca,y_test,cut_off_prob)\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2d4DEJBcw1gr"
   },
   "source": [
    "- Decision tree after selecting optimal cut-off also is resulting in a model with\n",
    "<br>**Train Recall : 89.78%**  and  **Train Roc_auc_score : 82.40**\n",
    "<br>**Test Recall : 78.13%**  and  **Test Roc_auc_score : 76.56**\n",
    "\n",
    "Random Forest still seems overfitted to the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ibcAPYP7w1gr"
   },
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9x27df2Dw1gs"
   },
   "source": [
    "##### Applying Random Forest Classifier on our principal components with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1nq4aUbCw1gs"
   },
   "outputs": [],
   "source": [
    "def plot_Accuracy(score,param):\n",
    "    scores = score\n",
    "    # plotting accuracies with max_depth\n",
    "    plt.figure()\n",
    "    plt.plot(scores[\"param_\"+param], \n",
    "    scores[\"mean_train_score\"], \n",
    "    label=\"training accuracy\")\n",
    "    plt.plot(scores[\"param_\"+param], \n",
    "    scores[\"mean_test_score\"], \n",
    "    label=\"test accuracy\")\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"f1\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T3Aa5rJsw1gt"
   },
   "source": [
    "#### Tuning max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcLFOjAWw1gt",
    "outputId": "3815d224-de79-493e-e128-50cff47277fb"
   },
   "outputs": [],
   "source": [
    "parameters = {'max_depth': range(10, 30, 5)}\n",
    "rf0 = RandomForestClassifier()\n",
    "rfgs = GridSearchCV(rf0, parameters, \n",
    "                    cv=5, \n",
    "                   scoring=\"f1\",return_train_score=True)\n",
    "rfgs.fit(X_train_pca,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39xJv9jyw1gx",
    "outputId": "86e33e18-3f31-4d67-984f-d542117ac282"
   },
   "outputs": [],
   "source": [
    "scores = rfgs.cv_results_\n",
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9hTULp06w1gy"
   },
   "source": [
    "Test f1-score almost becomes constant after max_depth=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9WuZSfww1g2"
   },
   "source": [
    "#### Tuning n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWiqB9X-w1g2"
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': range(50, 150, 25)}\n",
    "rf1 = RandomForestClassifier(max_depth=20,random_state=10)\n",
    "rfgs = GridSearchCV(rf1, parameters, \n",
    "                    cv=3, \n",
    "                   scoring=\"recall\",return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIHOqq0Cw1g3",
    "outputId": "bc6d9a0a-3e02-4c7b-8082-050525c47e2d"
   },
   "outputs": [],
   "source": [
    "rfgs.fit(X_train_pca,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SX9-R5juw1g4",
    "outputId": "c6034ff0-016c-4215-aa5a-ddd4c3923a91"
   },
   "outputs": [],
   "source": [
    "plot_Accuracy(rfgs.cv_results_,'n_estimators')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UhrCDKqyw1g5"
   },
   "source": [
    "Selecting n_estimators = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7YVGrqKw1g5"
   },
   "source": [
    "#### Tuning max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2BzJ6kAw1g5"
   },
   "outputs": [],
   "source": [
    "parameters = {'max_features': [4, 8, 14]}\n",
    "rf3 = RandomForestClassifier(max_depth=20,n_estimators=80,random_state=10)\n",
    "rfgs = GridSearchCV(rf3, parameters, \n",
    "                    cv=3, \n",
    "                   scoring=\"f1\",return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVC2mt3cw1g6",
    "outputId": "617905d2-227c-428d-daf8-fceaefa833d6"
   },
   "outputs": [],
   "source": [
    "rfgs.fit(X_train_pca,y_train_res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Accuracy(rfgs.cv_results_,'max_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oJ9rk-aw1g8"
   },
   "source": [
    "Selecting max_features = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ak4zK8ORw1g8"
   },
   "source": [
    "#### Tuning min_sample_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61tYYGDXw1g8"
   },
   "outputs": [],
   "source": [
    "parameters = {'min_samples_leaf': range(100, 400, 50)}\n",
    "rf4 = RandomForestClassifier(max_depth=20,n_estimators=80,max_features=5,random_state=10)\n",
    "rfgs = GridSearchCV(rf4, parameters, \n",
    "                    cv=3, \n",
    "                   scoring=\"f1\",return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3j8-O39w1g9",
    "outputId": "efbf4fec-fa01-41a7-beb6-de8311afa194"
   },
   "outputs": [],
   "source": [
    "rfgs.fit(X_train_pca,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Accuracy(rfgs.cv_results_,'min_samples_leaf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "708QXSomw1hB"
   },
   "source": [
    "Selecting min_sample_leaf = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCPOdDG7w1hC"
   },
   "source": [
    "#### Tuning min_sample_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmfgz2iqw1hC"
   },
   "outputs": [],
   "source": [
    "parameters = {'min_samples_split': range(150, 300, 50)}\n",
    "rf5 = RandomForestClassifier(max_depth=20,n_estimators=80,max_features=5,min_samples_leaf=100,random_state=10)\n",
    "rfgs = GridSearchCV(rf5, parameters, \n",
    "                    cv=3, \n",
    "                   scoring=\"f1\",return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pg1NOHK3w1hD",
    "outputId": "c748437b-cc8c-4f5f-f938-f622eaffad99"
   },
   "outputs": [],
   "source": [
    "rfgs.fit(X_train_pca,y_train_res)\n",
    "plot_Accuracy(rfgs.cv_results_,'min_samples_split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mfaaGBWpw1hD"
   },
   "source": [
    "Selecting min_sample_split = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yc7S_S7-w1hE"
   },
   "source": [
    "#### Tunned Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGnem99_w1hE"
   },
   "outputs": [],
   "source": [
    "rf_final = RandomForestClassifier(max_depth=20,\n",
    "                                  n_estimators=80,\n",
    "                                  max_features=3,\n",
    "                                  min_samples_leaf=100,\n",
    "                                  min_samples_split=50,\n",
    "                                  random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4eoZud2cw1hF",
    "outputId": "310623e7-866b-4035-a282-22435089e30e"
   },
   "outputs": [],
   "source": [
    "print(\"Train data Results:\")\n",
    "fit_model(rf_final,X_train_pca,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDqvkeGtw1hG"
   },
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "predictions = rf_final.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6Q0_FlFw1hH",
    "outputId": "0b34f150-7bb2-4fdd-92fe-4792b8e89054"
   },
   "outputs": [],
   "source": [
    "print(\"Test data Results:\")\n",
    "getModelMetricsResults(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ps5j9Bhfw1hK"
   },
   "source": [
    "After hyperparameter tuning for the random forest. The Recall rate(Test) is 73.11%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXoHArQqw1hK"
   },
   "source": [
    "Let's see if we can achive a better Recall rate by deciding an optimal cut-off for the model to predict churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_73q_ORw1hK",
    "outputId": "b21030af-ce86-4b52-8daf-1a462a914e51"
   },
   "outputs": [],
   "source": [
    "# predicting churn with default cut-off 0.5\n",
    "cut_off_prob=0.5\n",
    "y_train_df = predictChurnUsingProbCutOff(rf_final,X_train_pca,y_train_res,cut_off_prob)\n",
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iuevuj3fw1hL",
    "outputId": "1acc35c9-4d2f-478b-b17b-163bc3892079"
   },
   "outputs": [],
   "source": [
    "# finding cut-off with the right balance of the metrices\n",
    "findOptimalCutoff(y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7x1c1sQ0w1hM"
   },
   "source": [
    "**From the plot above, 0.45 is the optimal point with high enough sensitivity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chBp01Zjw1hM",
    "outputId": "68431683-fb0e-4669-ffcb-d79d21a46ab3"
   },
   "outputs": [],
   "source": [
    "cut_off_prob=0.45\n",
    "predictChurnUsingProbCutOff(rf_final,X_train_pca,y_train_res,cut_off_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ECt8XBALw1hN"
   },
   "source": [
    "**Making prediction on test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mJb2m5-w1hO",
    "outputId": "82cf8e43-8138-4f73-acf5-459ec5bd1dc9"
   },
   "outputs": [],
   "source": [
    "y_test_df= predictChurnUsingProbCutOff(rf_final,X_test_pca,y_test,cut_off_prob)\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5vBEjRXw1hO"
   },
   "source": [
    "- Random Forest after selecting optimal cut-off also is resulting in a model with\n",
    "<br>**Train Recall : 88.40%**  and  **Train Roc_auc_score : 85.17**\n",
    "<br>**Test Recall : 77.57%**  and  **Test Roc_auc_score : 79.33**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQfilg8ow1iJ"
   },
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAK656wEw1iJ"
   },
   "source": [
    "## Model Selection\n",
    "The company would like to identify most customers at risk of churning, even if there are many customers that are misclassified as churn. The cost to the company of churning is much higher than having a few false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9qJEWQXw1iJ"
   },
   "source": [
    "| Model                                 | Train  Results   | Test Results  |\n",
    "|---------------------------------------|------------------|---------------|\n",
    "| Logistic Regression ( cut-off = 0.45) |  ------------------------------  |\n",
    "| Roc_auc_score                         | 82.11%           | 81.21%        |\n",
    "| Sensitivity/Recall                    | 86.48%           | 84.40%        |\n",
    "| Specificity                           | 77.75%           | 78.02%        |\n",
    "| precision                             | 79.54%           | 25.04%        |\n",
    "| DecisionTree ( cut-off = 0.4)         |  ------------------------------  |\n",
    "| Roc_auc_score                         | 82.41%           | 76.57%        |\n",
    "| Sensitivity/Recall                    | 89.79%           | 78.13%        |\n",
    "| Specificity                           | 75.03%           | 75%           |\n",
    "| precision                             | 78.24%           | 21.38%        |\n",
    "| Random Forest (cut-off = 0.45)        |   -----------------------------  |\n",
    "| Roc_auc_score                         | 85.60%           | 96.53%        |\n",
    "| Sensitivity/Recall                    | 88.70%           | 77.57%        |\n",
    "| Specificity                           | 82.50%           | 81.73%        |\n",
    "| precision                             | 83.52%           | 26.97%        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyCaUjSow1iJ"
   },
   "source": [
    "Overall, the **Logistic Regression** model with probability cut-off = 0.45, performs best. It achieved the **best recall accuracy of 84.4%** for test data. Also the overall accuracy and specificity is consistent for Test and train data, thus avoiding overfitting. The precision is compromised in this effort but the business objective to predict Churn customers is most accuratety captured by it. \n",
    "\n",
    "From the Tree Family, the Decision Tree overfitted the data slightly while obtaining 78.13% recall accuracy on test data. \n",
    "The Random Forest avoided overfitting but obtained only 77.57% recall accuracy on test data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjB3mj5Qw1iJ"
   },
   "source": [
    "## Identifying relevant churn features. \n",
    "\n",
    "We will use an instance of Random Forest classifier to identify the features most relevant to churn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S1gKFJ0Pw1iK"
   },
   "source": [
    "### Random Forest for churn driver features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-An6owuw1iK"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [8,10,12],\n",
    "    'min_samples_leaf': range(100, 400, 200),\n",
    "    'min_samples_split': range(200, 500, 200),\n",
    "    'n_estimators': [100,200, 300], \n",
    "    'max_features': [12, 15, 20]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = 4,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H0ZaPxKWw1iL",
    "outputId": "4313ac4b-798e-4f3b-80ca-969f5bafeb4e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BicPUvQvw1iM",
    "outputId": "f05aa565-4af4-4c33-b275-b68de75a4f7e"
   },
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print(\"accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AgyYzKN-w1iN"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=12,\n",
    "                            max_features=20,\n",
    "                            min_samples_leaf=100,\n",
    "                            min_samples_split=200,\n",
    "                            n_estimators=300,\n",
    "                            random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12m0Ky7Qw1iO",
    "outputId": "7ff28b8f-5225-4494-f9ee-f8f9a3f4a660"
   },
   "outputs": [],
   "source": [
    "rf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sOxrWn1fw1iO",
    "outputId": "ff32dfc1-25ee-4cfd-ee4c-c5b7d9f0f98b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,40))\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(len(X.columns)).sort_values().plot(kind='barh', align='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oo9x6mxlyBr0"
   },
   "source": [
    "Some of the top main predictiors of churn are the monthly features for the action phase (3rd month August)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "voAggfHWw1iP"
   },
   "source": [
    "above plot shows that the top 25 features ranked in order of importance as produced by our RandomForest implementation are the features that belong to month 8 i.e., the action month. Hence, it is clear that what happens in the action phase has a direct impact on the customer churn of high value customers,features :-\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1.\t**total_ic_mou_8**\t\t-- *Total incoming minutes of usage in month 8*\n",
    "2.\t**loc_ic_mou_8**\t\t-- *local incoming minutes of usage in month 8*\n",
    "3.\t**total_month_rech_8**\t-- *Total month recharge amount in month 8*\t\n",
    "4.\t**total_roam_mou_8**\t-- *Total incoming+outgoing roaming minutes of usage in month 8*\n",
    "5.\t**loc_ic_t2m_mou_8**\t-- *local incoming calls to another operator minutes of usage in month 8*\n",
    "6.\t**roam_og_mou_8**\t\t-- *outgoing roaming calls minutes of usage in month 8*\n",
    "7.\t**Total_loc_mou_8**\t\t-- *Total local minutes of usage in month 8*\n",
    "8.\t**roam_ic_mou_8**\t\t-- *incoming roaming calls minutes of usage in month 8*\n",
    "9.\t**total_rech_amt_8**\t-- *total recharge amount in month 8*\n",
    "10.\t**loc_ic_t2t_mou_8**\t-- *local incoming calls from same operator minutes of usage in month 8*\n",
    "11.\t**max_rech_amt_8**\t\t-- *maximum recharge amount in month 8*\n",
    "12.\t**last_day_rch_amt_8**\t-- *last (most recent) recharge amount in month 8*\n",
    "13.\t**arpu_8**\t\t\t\t-- *average revenue per user in month 8*\n",
    "14.\t**loc_og_mou_8**\t\t-- *local outgoing calls minutes of usage in month 8*\n",
    "15.\t**loc_og_t2n_mou_8**\t-- *local outgoing calls minutes of usage to other operator mobile in month 8*\n",
    "16.\t**av_rech_amt_data_8**\t-- *average recharge amount for mobile data in month 8*\n",
    "17.\t**total_rech_data_8**\t-- *total data recharge (MB) in month 8*\n",
    "18.\t**total_og_t2t_mou_8**\t-- *total outgoing calls from same operator minutes of usage in month 8*\n",
    "19.\t**total_rech_num_8**\t-- *total number of recharges done in the month 8*\n",
    "20.\t**total_rech_amt_data_8**\t-- *total recharge amount for data in month 8*\n",
    "21.\t**max_rech_data_8**\t\t-- *maximum data recharge (MB) in month 8*\n",
    "22.\t**avg_rech_amt_8**\t\t-- *average recharge amount in month 8*\n",
    "23.\t**fb_user_8**\t\t\t-- *services of Facebook and similar social networking sites for month 8*\n",
    "24.\t**vol_data_mb_8**\t\t-- *volume of data (MB) consumed for month 8*\n",
    "25.\t**count_rech_2g_8**\t\t-- *Number of 2g data recharge in month 8*\n",
    "26.\t**loc_og_to_ic_mou_8**\t-- *local outgoing to incoming mou ratio for month of 8*\n",
    "27.\t**spl_og_mou_7**\t\t-- *Special outgoing call for the month of 7*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local calls Mou's be it incoming or outgoing have a very important role for churn predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "99pwzPygw1iU"
   },
   "source": [
    "## Approach to reduce customer churn\n",
    "\n",
    "It is a fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "For many incumbent operators, retaining high profitable customers is the number one business goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitoring Drop in usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer churn can be predicted by Usage based Churn, and it gives good accuracy.\n",
    "telecom company should pay close attention to drop in MoU, ARPU and data usage (2g and 3g) month over month.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieeViNBBw1iU"
   },
   "source": [
    "######  Outgoing services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vlVV0xEGw1iU",
    "outputId": "66db73b2-7d0a-43c7-992f-fa2334fe3b3b"
   },
   "outputs": [],
   "source": [
    "# Outgoing Mou\n",
    "plot_byChurnMou(outgoing_columns,'Outgoing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bp5tVLdiw1iW"
   },
   "source": [
    "-  Initially, churner's outgoing usage was more than that of non-churners. Gradually they dropped there outgoing usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GAA_AXYXw1iW"
   },
   "source": [
    "###### Roaming services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ht1El62w1iY",
    "outputId": "5ed3b021-637d-4418-c746-3697fb0138f6"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(highvalue_users,'Total_roam_mou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1AlbyM6gw1ia"
   },
   "source": [
    "Strategy Approach:-\n",
    "- Churners show higher roaming usage than non-churners.\n",
    "- The Network operators must further investigate their roaming tariffs, and quality of service.\n",
    "- Roaming tariffs offered are less competitive than their competitor.\n",
    "- Discounted roaming rates during particular hours of the day.\n",
    "- Free monthly roaming mou's depending on the users past roaming mou usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "qFQpGLvaw1d0",
    "o7WGRV_Hw1gN",
    "wUZpKshPw1gQ",
    "ibcAPYP7w1gr",
    "T3Aa5rJsw1gt",
    "K9WuZSfww1g2",
    "t7YVGrqKw1g5",
    "ak4zK8ORw1g8",
    "vCPOdDG7w1hC",
    "yc7S_S7-w1hE",
    "n40kKPV5w1hP",
    "G5kKREtHw1h3",
    "ZAK656wEw1iJ",
    "99pwzPygw1iU"
   ],
   "name": "Akshay_Final_Submission_Telecom Churn - ML Group Case Study.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
